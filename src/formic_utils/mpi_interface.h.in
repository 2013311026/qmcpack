///////////////////////////////////////////////////////////////////////////////////////////////////
/// \file formic/utils/mpi_interface.h
///
/// \brief   provides an interface to mpi
///
///////////////////////////////////////////////////////////////////////////////////////////////////

#ifndef FORMIC_MPI_INTERFACE_HEADER
#define FORMIC_MPI_INTERFACE_HEADER

#include <string>
#include <vector>
#include <complex>

#include <formic/utils/exception.h>
#include <formic/utils/matrix.h>

${MPI_COMMENT_I}#include <mpi.h>

${MPI_COMMENT_O}namespace MPI {
${MPI_COMMENT_O}
${MPI_COMMENT_O}  // declare some empty classes as placeholders if we are not using mpi
${MPI_COMMENT_O}  class Comm {};
${MPI_COMMENT_O}  class Op {};
${MPI_COMMENT_O}  class Datatype {};
${MPI_COMMENT_O}  extern MPI::Comm COMM_WORLD;
${MPI_COMMENT_O}  extern MPI::Op SUM;
${MPI_COMMENT_O}  extern MPI::Datatype CHAR;
${MPI_COMMENT_O}  extern MPI::Datatype SHORT;
${MPI_COMMENT_O}  extern MPI::Datatype INT;
${MPI_COMMENT_O}  extern MPI::Datatype LONG;
${MPI_COMMENT_O}  extern MPI::Datatype SIGNED_CHAR;
${MPI_COMMENT_O}  extern MPI::Datatype UNSIGNED_CHAR;
${MPI_COMMENT_O}  extern MPI::Datatype UNSIGNED_SHORT;
${MPI_COMMENT_O}  extern MPI::Datatype UNSIGNED;
${MPI_COMMENT_O}  extern MPI::Datatype UNSIGNED_LONG;
${MPI_COMMENT_O}  extern MPI::Datatype FLOAT;
${MPI_COMMENT_O}  extern MPI::Datatype DOUBLE;
${MPI_COMMENT_O}  extern MPI::Datatype LONG_DOUBLE;
${MPI_COMMENT_O}  extern MPI::Datatype BOOL;
${MPI_COMMENT_O}  extern MPI::Datatype COMPLEX;
${MPI_COMMENT_O}  extern MPI::Datatype DOUBLE_COMPLEX;
${MPI_COMMENT_O}  extern MPI::Datatype LONG_DOUBLE_COMPLEX;
${MPI_COMMENT_O}
${MPI_COMMENT_O}  inline double Wtime() { return double(std::clock()) / double(CLOCKS_PER_SEC); }
${MPI_COMMENT_O}
${MPI_COMMENT_O}}

namespace formic {

  class Archive;

///////////////////////////////////////////////////////////////////////////////////////////////////
/// \brief   namespace to hold mpi related functions
///
///////////////////////////////////////////////////////////////////////////////////////////////////

namespace mpi {

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   returns the global communicator
  ///
  /// \return the global communicator
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  inline const MPI::Comm & world() {
    return MPI::COMM_WORLD;
  }

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   returns the number of processes in a communicator
  ///
  /// \param[in]     comm     the communicator to use (defaults to MPI::COMM_WORLD)
  ///
  /// \return the number of processes in comm
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  inline int size(const MPI::Comm & comm = MPI::COMM_WORLD) {
    ${MPI_COMMENT_I}return comm.Get_size();
    ${MPI_COMMENT_O}return 1;
  }

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   returns rank of the current process in a communicator
  ///
  /// \param[in]     comm     the communicator to use (defaults to MPI::COMM_WORLD)
  ///
  /// \return the rank of the current process in comm
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  inline int rank(const MPI::Comm & comm = MPI::COMM_WORLD) {
    ${MPI_COMMENT_I}return comm.Get_rank();
    ${MPI_COMMENT_O}return 0;
  }

  void init(int argc, char **argv);
  void finalize();
  //std::string get_hostname();

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   waits for all processes in the communicator
  ///
  /// \param[in]     comm     the communicator to use (defaults to MPI::COMM_WORLD)
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  inline void barrier(const MPI::Comm & comm = MPI::COMM_WORLD) {
    ${MPI_COMMENT_I}comm.Barrier();
  }

  // declare mpi templates, setting the default communicator to the global communicator
  template<class T> void bcast(T * data, size_t n, int root = 0,
                               const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void reduce(const T * send_buf, T * recv_buf, size_t n, const MPI::Op & op, int root = 0,
                                const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void allreduce(const T * send_buf, T * recv_buf, size_t n, const MPI::Op & op,
                                   const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void send(const T * buf, size_t n, const int dest, const int tag,
                              const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void recv(T * buf, size_t n, const int source, const int tag,
                              const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void scatter(const T * send_buf, T * recv_buf, size_t n, int root = 0,
                                 const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void gather(const T * send_buf, T * recv_buf, size_t n, int root = 0,
                                const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void allgather(const T * send_buf, T * recv_buf, size_t n,
                                   const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void bcast(std::vector<T> & v, int root = 0, const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void reduce(const std::vector<T> & send_v, std::vector<T> & recv_v,
                                const MPI::Op & op, int root = 0, const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void allreduce(const std::vector<T> & send_v, std::vector<T> & recv_v,
                                   const MPI::Op & op, const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void send(const std::vector<T> & v, const int dest, const int tag,
                              const MPI::Comm & comm = MPI::COMM_WORLD);
  template<class T> void recv(std::vector<T> & v, const int source, const int tag,
                              const MPI::Comm & comm = MPI::COMM_WORLD);

//  template<class T> void bcast(T * const data, size_t n, int root = 0,
//                               const MPI::Comm & comm = MPI::COMM_WORLD) {
//    T * data_ptr = data;
//    formic::mpi::bcast(data_ptr, n, root, comm);
//  }

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   broadcast a single item
  ///
  /// \param[inout]  datum      the item to be broadcast
  /// \param[in]     root       the process from which to broadcast
  /// \param[in]     comm       the communicator to use
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  template<class T> inline void bcast(T & datum, int root = 0, const MPI::Comm & comm = MPI::COMM_WORLD) {
    formic::mpi::bcast(&datum, 1, root, comm);
  }

  void bcast(std::string & s, int root = 0, const MPI::Comm & comm = MPI::COMM_WORLD);

  void bcast(std::vector<std::string> & v, int root = 0, const MPI::Comm & comm = MPI::COMM_WORLD);

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   broadcast a Matrix
  ///
  /// \param[inout]  mat        the matrix to be broadcast
  /// \param[in]     root       the process from which to broadcast
  /// \param[in]     comm       the communicator to use
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  template<class S> inline void bcast(formic::Matrix<S> & mat, int root = 0, const MPI::Comm & comm = MPI::COMM_WORLD) {
    unsigned long int n = mat.rows();
    unsigned long int m = mat.cols();
    formic::mpi::bcast(n, root, comm);
    formic::mpi::bcast(m, root, comm);
    if ( mat.rows() != n || mat.cols() != m )
      mat.reset(n,m);
    if ( mat.size() > 0 )
      formic::mpi::bcast(mat.begin(), mat.size(), root, comm);
  }

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   broadcast a ColVec
  ///
  /// \param[inout]  vec        the vector to be broadcast
  /// \param[in]     root       the process from which to broadcast
  /// \param[in]     comm       the communicator to use
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  template<class S> inline void bcast(formic::ColVec<S> & vec, int root = 0, const MPI::Comm & comm = MPI::COMM_WORLD) {
    unsigned long int n = vec.size();
    formic::mpi::bcast(n, root, comm);
    if ( vec.size() != n )
      vec.reset(n);
    if ( vec.size() > 0 )
      formic::mpi::bcast(vec.begin(), vec.size(), root, comm);
  }

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   broadcast a RowVec
  ///
  /// \param[inout]  vec        the vector to be broadcast
  /// \param[in]     root       the process from which to broadcast
  /// \param[in]     comm       the communicator to use
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  template<class S> inline void bcast(formic::RowVec<S> & vec, int root = 0, const MPI::Comm & comm = MPI::COMM_WORLD) {
    unsigned long int n = vec.size();
    formic::mpi::bcast(n, root, comm);
    if ( vec.size() != n )
      vec.reset(n);
    if ( vec.size() > 0 )
      formic::mpi::bcast(vec.begin(), vec.size(), root, comm);
  }

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   reduces a formic::Matrix
  ///
  /// \param[in,out]  mat        the matrix to be reduced
  /// \param[in]      root       the process from which to broadcast
  /// \param[in]      comm       the communicator to use
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  template<class S> inline void reduce(formic::Matrix<S> & mat, int root = 0, const MPI::Comm & comm = MPI::COMM_WORLD) {
    if ( formic::mpi::rank() == root )
      formic::mpi::reduce(mat.clone().begin(), mat.begin(), mat.size(), MPI::SUM, root, comm);
    else
      formic::mpi::reduce(        mat.begin(), mat.begin(), mat.size(), MPI::SUM, root, comm);
  }

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   allreduces a formic::Matrix
  ///
  /// \param[in,out]  mat        the matrix to be reduced
  /// \param[in]      comm       the communicator to use
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  template<class S> inline void allreduce(formic::Matrix<S> & mat, const MPI::Comm & comm = MPI::COMM_WORLD) {
    formic::mpi::allreduce(mat.clone().begin(), mat.begin(), mat.size(), MPI::SUM, comm);
  }

  ///////////////////////////////////////////////////////////////////////////////////////////////////
  /// \brief   returns the appropriate MPI datatype
  ///
  /// \return the appropriate MPI datatype
  ///
  ///////////////////////////////////////////////////////////////////////////////////////////////////
  template<class T> inline const MPI::Datatype & datatype() {
    throw formic::Exception("unknown mpi datatype");
    return MPI::DOUBLE;
  }
  template <> inline const MPI::Datatype & datatype< char                      >() { return MPI::CHAR;                }
  template <> inline const MPI::Datatype & datatype< signed short              >() { return MPI::SHORT;               }
  template <> inline const MPI::Datatype & datatype< signed int                >() { return MPI::INT;                 }
  template <> inline const MPI::Datatype & datatype< signed long               >() { return MPI::LONG;                }
  template <> inline const MPI::Datatype & datatype< signed char               >() { return MPI::SIGNED_CHAR;         }
  template <> inline const MPI::Datatype & datatype< unsigned char             >() { return MPI::UNSIGNED_CHAR;       }
  template <> inline const MPI::Datatype & datatype< unsigned short            >() { return MPI::UNSIGNED_SHORT;      }
  template <> inline const MPI::Datatype & datatype< unsigned int              >() { return MPI::UNSIGNED;            }
  template <> inline const MPI::Datatype & datatype< unsigned long int         >() { return MPI::UNSIGNED_LONG;       }
  template <> inline const MPI::Datatype & datatype< float                     >() { return MPI::FLOAT;               }
  template <> inline const MPI::Datatype & datatype< double                    >() { return MPI::DOUBLE;              }
  template <> inline const MPI::Datatype & datatype< long double               >() { return MPI::LONG_DOUBLE;         }
  template <> inline const MPI::Datatype & datatype< bool                      >() { return MPI::BOOL;                }
  template <> inline const MPI::Datatype & datatype< std::complex<float>       >() { return MPI::COMPLEX;             }
  template <> inline const MPI::Datatype & datatype< std::complex<double>      >() { return MPI::DOUBLE_COMPLEX;      }
  template <> inline const MPI::Datatype & datatype< std::complex<long double> >() { return MPI::LONG_DOUBLE_COMPLEX; }

  template<class T> void read_and_bcast(formic::Archive & arch,
                                        T & val,
                                        const std::string & error_msg = "failed to read from archive in read_and_bcast",
                                        int root = 0,
                                        const MPI::Comm & comm = MPI::COMM_WORLD);

} // end namespace mpi

} // end namespace formic

#endif
