\section{Wavefunction Optimization}
Optimizing wavefunction is critical in all kinds of real-space quantum Monte Carlo calculations
because it significantly improves both the accuracy and efficiency of computation.
However, it is very difficult to directly adopt deterministic minimization approaches due to the stochastic nature of evaluating quantities with Monte Carlo.
Thanks to the algorithmic breakthrough during the first decade of this century and the tremendous computer power available, 
it becomes feasible to optimize tens of thousands of parameters in a wavefunction for a solid or molecule.
QMCPACK has multiple optimizers implemented based on the state-of-the-art linear method.
We are continually improving our optimizers for the robustness and friendliness and trying to provide a single solution.
Due to the large variation of wavefunction types carrying distinct characteristics, using several optimizer may be needed in some cases.
It is highly suggested to read the recommendation from the experts maintaining these optimizers.

A typical optimization block looks like the following. It starts with method=``linear" and contains three blocks of parameters.
\begin{lstlisting}
 <loop max="10">
  <qmc method="linear" move="pbyp" gpu="yes">
    <!-- Specify the VMC options -->
    <parameter name="walkers">    256 </parameter>
    <parameter name="samples">    2867200 </parameter>
    <parameter name="stepsbetweensamples">    1 </parameter>
    <parameter name="substeps">  5 </parameter>
    <parameter name="warmupSteps">  5 </parameter>
    <parameter name="blocks">  70 </parameter>
    <parameter name="timestep">  1.0 </parameter>
    <parameter name="usedrift">   no </parameter>
    <estimator name="LocalEnergy" hdf5="no"/>
    ...
    <!-- Specify the correlated sampling options and define the cost function -->
    <parameter name="usebuffer"> no </parameter>
    <parameter name="nonlocalpp"> yes </parameter>
         <cost name="energy">                   0.95 </cost>
         <cost name="unreweightedvariance">     0.00 </cost>
         <cost name="reweightedvariance">       0.05 </cost>
    ...
    <!-- Specify the optimizer options -->
    <parameter name="MinMethod">quartic</parameter>
    <parameter name="exp0">-6</parameter>
    <parameter name="alloweddifference"> 1.0e-4 </parameter>
    <parameter name="nstabilizers"> 1 </parameter>
    <parameter name="bigchange">15.0</parameter>
    ...
  </qmc>
 </loop>
\end{lstlisting}
\begin{itemize}
\item loop is helpful to execute identical optimization blocks repeatedly.
\item The first part is highly identical to a regular VMC block.
\item The second part is to specify the correlated sampling options and define the cost function.
\item The last part is used to specify the options of different optimizers. They can be very distinct from one optimizer to another.
\end{itemize}

\subsection{VMC run for the optimization}
The VMC calculation for the wavefunction optimization has a strict requirement 
that samples or samplesperthread must be specified because of the optimizer needs for the stored samples.
The input parameters of this part are identical to the VMC method.

Recommendations:
\begin{itemize}
\item Run the inclusive VMC calculation correctly and efficiently, because the this part takes significant amount of time in optimization.
For example, make sure the derived steps per block is 1 and use larger substeps to control the correlation between samples.
\item A reasonable starting wavefunction is necessary. A lot of optimization fails because of a bad wavefunction starting point.
The sign of a bad initial wavefunction includes but not limited to very long equilibration time, low acceptance ratio and huge variance.
The first thing to do after a failed optimization is to check the information provided by the VMC calculation via *.scalar.dat files.
\end{itemize}

\subsection{Correlated sampling and Cost function}
After generating the samples with VMC, the derivatives of the wavefunction with respect to the parameters are computed for proposing a new set of parameters by optimizers.
And later, a correlated sampling calculation is performed to quickly evaluate values of the cost function on the old set of parameters and the new set for the further decisions.
The input parameters are listed in the following table.
\begin{table}[h]
\begin{center}
\begin{tabularx}{\textwidth}{l l l l l l }
\hline
\multicolumn{6}{l}{\texttt{linear} method} \\
\hline
\multicolumn{2}{l}{parameters}  & \multicolumn{4}{l}{}\\
   &   \bfseries name     & \bfseries datatype & \bfseries values & \bfseries default   & \bfseries description \\
   &   \texttt{usebuffer} &  text     & yes, minimum, no & no  & buffer info to speed up the correlated sampling\\
   &   \texttt{nonlocalpp} &  text     & yes, no & no  & include non-local PP energy in the cost function\\
%   &   \texttt{GEVMethod} &  text     & mixed, H2 & mixed  & methods of generalized eigenvalue problem\\
%   &   \texttt{beta} &  real     & any value & 0.0  & a parameter for GEVMethod\\
%   &   \texttt{use\_nonlocalpp\_deriv} &  text     & yes, no & no  & include the derivatives of non-local PP\\
   &   \texttt{minwalkers} &  real     & 0--1   & 0.3 & lower bound of the effective weight\\
   &   \texttt{maxWeight} &  real     & $>1$   & 1e6 & Maximum weight allowed in reweighting\\
  \hline
\end{tabularx}
\end{center}
\end{table}

Additional information:
\begin{itemize}
\item \texttt{maxWeight}. The default should be good.
\item \texttt{usebuffer}. It saves a lot of computation especially with the `quartic' optimizer.
\item \texttt{nonlocalpp}. It is recommended to enable it when 3 body Jastrow is on. GPU code has a implementation issue that large amount of memory is consumed with this option.
\item \texttt{minwalkers}. A CRITICAL parameter. When the ratio of effective samples to actual number of walkers in a reweighting step, 
the proposed set of parameters is unjustified. The last set of acceptable parameters are kept.
\end{itemize}

The cost function consists of three components: energy, unreweighted variance and reweighted variance.
\begin{lstlisting}
     <cost name="energy">                   0.95 </cost>
     <cost name="unreweightedvariance">     0.00 </cost>
     <cost name="reweightedvariance">       0.05 </cost>
\end{lstlisting}

\subsection{Optimizers}
QMCPACK implements a few optimizers having different preference aiming for different priorities.
They can be switched among `rescale', `quartic' (default), `adaptive' and `OneShiftOnly' by the following line in the optimization block.
\begin{lstlisting}
<parameter name="MinMethod"> THE METHOD YOU LIKE </parameter>
\end{lstlisting}

\subsubsection{quartic}
The quartic optimizer fits a quartic polynomial to 7 values of the cost function obtained using reweighting along chosen direction and determines the optimal move.
This optimizer is very robust but a bit conservative to accept new steps especially when large parameters changes are proposed.
\begin{table}[h]
\begin{center}
\begin{tabularx}{\textwidth}{l l l l l l }
\hline
\multicolumn{6}{l}{\texttt{linear} method} \\
\hline
\multicolumn{2}{l}{parameters}  & \multicolumn{4}{l}{}\\
   &   \bfseries name     & \bfseries datatype & \bfseries values & \bfseries default   & \bfseries description \\
   %&   \texttt{stepsize} &  real     & 0--1 & 0.25  & Step size for moving parameters\\
   &   \texttt{bigchange} &  real     & $>0$ & 50.0  & Largest parameter change allowed\\
   &   \texttt{alloweddifference} &  real     & $>0$ & 1e-4 & Allowed increased in energy\\
   &   \texttt{exp0} &  real     & any value & -16.0 & Initial value for stabilizer\\
   &   \texttt{stabilizerscale} &  real     & $>0$ & 2.0 & Increase in value of exp0 between iterations\\
   &   \texttt{nstabilizers} &  integer     & $>0$ & 3 & Number of stabilizers to try\\
   &   \texttt{max\_its} &  integer   & $>0$ & 1 & Number of inner loops with same samples\\
  \hline
\end{tabularx}
\end{center}
\end{table}

Additional information:
\begin{itemize}
\item \texttt{exp0}. It is the initial value for stabilizer (shift to diagonal of H). The actual value of stabilizer is $10^\textrm{exp0}$.
\end{itemize}

Recommendations:
\begin{itemize}
  \item{For hard cases (e.g. simultaneous optimization of long MSD and 3-Body J), set exp0
to 0 and do a single inner iteration (max its=1) per sample of configurations.}
\end{itemize}

\begin{lstlisting}
    <!-- Specify the optimizer options -->
    <parameter name="MinMethod">quartic</parameter>
    <parameter name="exp0">-6</parameter>
    <parameter name="alloweddifference"> 1.0e-4 </parameter>
    <parameter name="nstabilizers"> 1 </parameter>
    <parameter name="bigchange">15.0</parameter>
\end{lstlisting}

\subsubsection{adaptive}

The default setting of the adaptive optimizer is to construct the linear method Hamiltonian and overlap matrices explicitly and add different shifts to the Hamiltonian matrix 
as ``stablizers''. The generalized eigenvalue problem is solved for each shifted Hamiltonian and updates to wave function parameters are obtainted. Then a correlated sampling 
is performed using the middle shift's updated wave function as the guiding function for each shift's updated wave function and initial trial wave function. The final step is 
to compare different shift's cost function with the initial value and apply the best update to wave function parameters corresponding to the lowest cost function. 

Thanks to the recently developed excited states variational principle, adaptive optimizer is also able to optimize individual excited states directly.  
It tries to optimize the following functional: 
\begin{equation*}
\Omega[\Psi]=\frac{\left<\Psi|\omega-H|\Psi\right>}{\left<\Psi|{\left(\omega-H\right)}^2|\Psi\right>}
\end{equation*}
The global minimal of this functional corresponds to the state whose energy lies right above the shift parameter $\omega$ in energy spectrum. Thus, suppose the initial 
trial wave function's parameters are close to that of the first excited state, then by setting $\omega$ to be a value in between ground state and first excited state 
energy would drive the trial wave function to represent the first excited state. 

When the trial wave function contains more than tens of thousands of parameters, constructing and storing the linear method matrices become a memory bottleneck. 
To avoid explicit
construction of these matrices, adaptive optimizer implements recently developed ``block linear method''. Block linear method (BLM) tries to find an approximate 
solution $\vec{c}_{opt}$ to the standard LM generalized eigenvalue problem by (a) dividing the variable space into a number of blocks (b) making intelligent estimates for which 
directions within those blocks will be most important for constructing $\vec{c}_{opt}$, and (c) estimating $\vec{c}_{opt}$ by solving a smaller, more memory-efficient 
eigenproblem in the basis of these supposedly important block-wise directions. 

\begin{table}[h]
\begin{center}
\begin{tabularx}{\textwidth}{l l l l l l }
\hline
\multicolumn{6}{l}{\texttt{linear} method} \\
\hline
\multicolumn{2}{l}{parameters}  & \multicolumn{4}{l}{}\\
   &   \bfseries name     & \bfseries datatype & \bfseries values & \bfseries default   & \bfseries description \\
   %&   \texttt{stepsize} &  real     & 0--1 & 0.25  & Step size for moving parameters\\
   &   \texttt{max\_relative\_change} &  real     & $>0$ & 10.0 & Allowed change in cost function\\
   &   \texttt{max\_param\_change} &  real     & $>0$ & 0.3 & Allowed change in wave function parameter\\
   &   \texttt{shift\_i} &  real     & $>0$ & 0.01 & Direct stabilizer added to the Hamiltonian matrix\\
   &   \texttt{shift\_s} &  real     & $>0$ & 1.00 & Initial stabilizer based on the overlap matrix\\
   &   \texttt{targetExcited} &  text   & yes, no & no & Target excited state\\
   &   \texttt{omega} &  real   & $<0$ & & Energy shift used to target different excited state\\
   &   \texttt{chase\_lowest} &  text   & yes, no & yes & Chase the lowest eigenvector in iterative solver\\
   &   \texttt{chase\_closest} &  text   & yes, no & no & Chase the eigenvector closest to initial guess\\
   &   \texttt{block\_lm} &  text   & yes, no & no & Use block linear method\\
   &   \texttt{nblocks} &  integer   & $>0$ &  & \# of blocks in BLM\\
   &   \texttt{nolds} &  integer   & $>0$ &  & \# of old update vectors used in BLM\\
   &   \texttt{nkept} &  integer   & $>0$ &  & \# of eigenvectors to keep per block in BLM\\
  \hline
\end{tabularx}
\end{center}
\end{table}

Additional information:
\begin{itemize}
  \item \texttt{shift\_i}.  This is the initial value of direct term added to the diagonal of the Hamiltonian matrix. 
                            More stable but slower optimization with a large value. The used value is auto-adjusted by the optimizer. 
  \item \texttt{shift\_s}.  This is the initial value of the stabilizer based on the overlap matrix added to the Hamiltonian matrix. 
                            More stable but slower optimization with a large value. The used value is auto-adjusted by the optimizer. 
  \item \texttt{omega}.     Since approximate wave function has a finite variance of energy, is has been proved that the $\omega$ value
                            needs to be ``shifted down'' by the amount of the standard deviation of the energy to target the correct state. 
  \item \texttt{nblocks}.   This is the number of blocks used in block LM. The amount of memory required to store LM matrices decreases
                            with increased number of blocks. But the error introduced by BLM would increase with number of blocks.  
  \item \texttt{nolds}.     In BLM, the inter-block correlation is accounted for by including a small number of wave function update vectors
                            outside the block. Larger \texttt{nolds} would include more inter-block correlation and more accurate results, but 
                            also higher memory requirements. 
  \item \texttt{nkept}.     This is the number of update directions taken from each block in BLM. If all directions are taken in each block, 
                            BLM becomes standard LM and no approximation is made. Normally taking less than 5 directions in each block would 
                            be sufficient. 
                            
\end{itemize}


Recommendations:
\begin{itemize}
  \item Default shift\_i, shift\_s should be fine. 
  \item In order to obtain an unbiased excitation energy, one would need to optimize ground state with excited state variational principle by setting
        \texttt{omega} below ground state energy. Using ground state variational principle and excited state variational principle for ground and excited
        state respectively would create a bias for ground state. 
  \item Setting $\omega$ correctly is very important since a too low or too high $\omega$ will lead to a failure of the optimization. I recommend that one use
        $\omega$ as $E-\sigma$, in which $E$ and $\sigma$ being energy and standard deviation of the unoptimized wave function. 
  \item Block LM has a higher stochastic prefactor than standard LM. Thus it is not necessary to use it for less than 5,000 variables where memory is not a issue.  
  \item If the wave function contains more than 10,000 variables, using BLM could significantly reduce memory requirements. 
  \item For BLM, using a few hundred blocks and a handful of \texttt{nolds} and \texttt{nkept} would be enough to balance memory requirement and accuracy. 
\end{itemize}

\begin{lstlisting}
    <!-- Specify the optimizer options -->
    <parameter name="MinMethod">adaptive</parameter>
    <parameter name="max_relative_cost_change">10.0</parameter>
    <parameter name="shift_i"> 1.00 </parameter>
    <parameter name="shift_s"> 1.00 </parameter>
    <parameter name="max_param_change"> 0.3 </parameter>
    <parameter name="targetExcited"> yes </parameter>
    <parameter name="omega"> -380.00 </parameter>
    <parameter name="chase_lowest"> yes </parameter>
    <parameter name="chase_closest"> yes </parameter>
    <parameter name="block_lm"> yes </parameter>
    <parameter name="nblocks"> 100 </parameter>
    <parameter name="nolds"> 5 </parameter>
    <parameter name="nkept"> 3 </parameter>
\end{lstlisting}
%To activate this optimizer, add ``-D BUILD\_LMYENGINE\_INTERFACE=1'' in the CMake command line.

\subsubsection{OneShiftOnly}
The OneShiftOnly optimizer targets a fast optimization by moving parameters more aggressively. It works with threading and can be considered for large solids.
This method relies on ``minwalkers'' to justify a new set of parameters. If it is valid, the new set is taken no matter if the cost function value decreases or not.
If a proposed set is rejected, the standard output prints the measured ratio of effective samples to actual number of walkers and adjustment on ``minwalkers''can be made if needed.

\begin{table}[h]
\begin{center}
\begin{tabularx}{\textwidth}{l l l l l l }
\hline
\multicolumn{6}{l}{\texttt{linear} method} \\
\hline
\multicolumn{2}{l}{parameters}  & \multicolumn{4}{l}{}\\
   &   \bfseries name     & \bfseries datatype & \bfseries values & \bfseries default   & \bfseries description \\
   &   \texttt{shift\_i} &  real     & $>0$ & 0.01 & Direct stabilizer added to the Hamiltonian matrix\\
   &   \texttt{shift\_s} &  real     & $>0$ & 1.00 & Initial stabilizer based on the overlap matrix\\
  \hline
\end{tabularx}
\end{center}
\end{table}

Additional information:
\begin{itemize}
\item \texttt{shift\_i}. This is the direct term added to the diagonal of the Hamiltonian matrix.
                         More stable but slower optimization with a large value.
\item \texttt{shift\_s}. This is the initial value of the stabilizer based on the overlap matrix added to the Hamiltonian matrix. 
                         More stable but slower optimization with a large value. The used value is auto-adjusted by the optimizer.
\end{itemize}


Recommendations:
\begin{itemize}
  \item Default shift\_i, shift\_s should be fine.
  \item For hard cases, increasing shift\_i (factor of 5 or 10) can significantly stabilize the optimization by reducing the pace towards the optimal parameter set.
  \item If the VMC energy of the last optimization iterations grows significantly, increase minwalkers closer to 1 and make the optimization stable.
  \item If the first iterations of optimization are rejected on a reasonable initial wavefunction, 
        lower the minwalkers value based on the measured value printed in the standard output to accept the move.
\end{itemize}

It is recommended to use this optimizer in two sections with a very small minwalkers in the first and very large value in the second like the following.
\begin{lstlisting}
 <loop max="6">
  <qmc method="linear" move="pbyp" gpu="yes">
    <!-- Specify the VMC options -->
    ...
    <!-- Specify the correlated sampling options and define the cost function -->
    <parameter name="minwalkers"> 1e-4 </parameter>
    ...
    <!-- Specify the optimizer options -->
    <parameter name="MinMethod">OneShiftOnly</parameter>
  </qmc>
 </loop>
 <loop max="12">
  <qmc method="linear" move="pbyp" gpu="yes">
    <!-- Specify the VMC options -->
    ...
    <!-- Specify the correlated sampling options and define the cost function -->
    <parameter name="minwalkers"> 0.5 </parameter>
    ...
    <!-- Specify the optimizer options -->
    <parameter name="MinMethod">OneShiftOnly</parameter>
  </qmc>
 </loop>
\end{lstlisting}

\subsection{General recommendations}
Here are a few reminders to make wavefunction easier.
\begin{itemize}
\item All electron wavefunctions are more difficult to optimize than pseudopotential ones especially when the cusp is not removed.
\item Two body Jastrow contributes the largest portion of correlation energy from bare Slater determinants. It's also the easiest part for optimizer and gains most. For this reason, the recommend order optimizing wavefunction components is two-body, one-body, three-body Jastrow factors and MSD coefficients.
\item Never use all-zero two-body spline Jastrow and always start from a reasonable one. 
      You might want to bang your head against a brick wall for a bad two-body Jastrow.
\item One-body spline Jastrow from old calculations can be good starting point.
\item Three-body polynomial Jastrow should start from zero.
\end{itemize}

\label{sec:optimization}

